# LLM Provider Selection
# Options: bedrock, nova_internal, openai, anthropic, ollama
LLM_PROVIDER=bedrock

# AWS Bedrock Configuration (if using bedrock)
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=your_access_key_here
AWS_SECRET_ACCESS_KEY=your_secret_key_here
BEDROCK_MODEL_ID=amazon.nova-pro-v1:0

# Internal Amazon Nova API (if using nova_internal)
# NOVA_API_URL=https://internal.nova.amazon.com/api
# NOVA_API_KEY=your_nova_api_key_here
# NOVA_MODEL=nova-pro

# Alternative LLM Providers (uncomment to use)
# OPENAI_API_KEY=your_openai_key_here
# ANTHROPIC_API_KEY=your_anthropic_key_here

# Application Configuration
LOG_LEVEL=INFO
MAX_PARALLEL_FILES=4
DATABASE_URL=sqlite:///./memory_bank.db

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
# API_KEY=your_api_key_here  # Optional: Uncomment to enable API key authentication

# Analysis Configuration
DEFAULT_ANALYSIS_DEPTH=standard
COMPLEXITY_THRESHOLD=10

# Docker Compose Configuration
CODEBASE_PATH=./  # Path to codebase to analyze (mounted as /workspace in container)

# PostgreSQL Configuration (if using PostgreSQL instead of SQLite)
# POSTGRES_USER=codereviewer
# POSTGRES_PASSWORD=changeme
# DATABASE_URL=postgresql://codereviewer:changeme@postgres:5432/code_review_agent
